{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2163429-5432-44d5-a6dc-0e3460da8324",
   "metadata": {},
   "source": [
    "    MLP\n",
    "        Dense net 전체 특징에 대해서 계산, 특징 간의 관계가 훼손됨\n",
    "        CNN 일부 특징에 대해서 계산\n",
    "\n",
    "        Pre-Trained Model\n",
    "            이미 훈련된/디자인된 모델을 그대로 사용\n",
    "            네트워크 앞 부분은 일반적인 특징을 추출하지만 뒤로 갈수록 구체적으로 변하기 때문에 뒷 부분만 바꿔주면 모델을 재사용할 수 있음\n",
    "\n",
    "        Fine Tuning ( 미세조정 )\n",
    "            이미 훈련된 모델은 정답에 근사한 값을 가지고 있기 때문에 뒤에 넣은 모델에 맞게 다시 전체를 학습하여도 앞 부분은 값을 조정하는 범위가 작음\n",
    "\n",
    "        Data Argumentation\n",
    "            데이터가 적기 때문에 데이터를 늘리는 기술\n",
    "            데이터가 부족 -> 과소적합 발생\n",
    "            데이터가 많아질 수 있지만 다양성이 여전히 부족할 수 있음\n",
    "\n",
    "            SMOTE\n",
    "                주변 위치에 근사한 위치에 새로운 데이터 생성하여 데이터의 양을 늘림\n",
    "                Under-Sampling\n",
    "                    소수의 데이터 양에 맞추어서 랜덤으로 비교적 많은 데이터를 뽑아 줄이는 방법\n",
    "                Over-Sampling\n",
    "                    소수의 데이터 양을 늘리는 방법\n",
    "\n",
    "    RNN ( 순환신경망 )\n",
    "        시계열 데이터\n",
    "            과거 사건과 현재 사건이 연관되어 있음\n",
    "\n",
    "        CNN은 현재 입력에 대해서만 결과를 도출하만\n",
    "        RNN은 현재 입력만 처리하는 것이 아닌 현재 입력과 과거의 은닉 상태에 대해서 처리\n",
    "        \n",
    "        Ht = fW(Ht-1, xt)\n",
    "        Ht = 은닉 생태 = tanh(WxxT + WhHt-1)\n",
    "        xt = 입력\n",
    "        출력 = f(W*Ht)\n",
    "        fW = 가중치 W\n",
    "        \n",
    "        순환 데이터\n",
    "            Sliding Window\n",
    "                순환 신경망을 학습시키려면 데이터를 일정한 길이( Window Size )로 잘라서 여러 개의 훈련 샘플을 만들어야 함\n",
    "                \n",
    "        일대일\n",
    "            단일 입력 단일 출력\n",
    "        일대다\n",
    "            단일 입력 다중 출력\n",
    "        다대일\n",
    "            다중 입력 단일 출력\n",
    "        다대다\n",
    "            다중 입력 다중 출력\n",
    "\n",
    "        BPTT ( Backpropagation Through Time ) ( 시간에 따른 역전파 )\n",
    "            레이어가 많아짐으로 인해서 그레디언트 폭발, 손실 발생\n",
    "\n",
    "            그래디언트 클리핑\n",
    "                그래디언트 폭발이 발생하면 일정 수준 이하로 변경\n",
    "\n",
    "    LSTM ( Long Short Term Memory )\n",
    "        RNN의 그래디언트 손실 발생 문제를 해결하기 위해 개발\n",
    "        셀 = 장기 기억에 저장\n",
    "        업데이트 = 셀 정보를 선택적으로 업데이트\n",
    "        게이트 = 셀에 정보를 저장할 것인지 판단\n",
    "            삭제 게이트 = 관련 없는 셀 정보를 삭제\n",
    "            저장 ( 입력 ) 게이트 = 셀에 어떠한 정보를 저장할 것인지 ( 입력과 은닉 상태에 대해서 시그모이드 ( 0 ~ 1 ) )\n",
    "            출력 게이트 = 다름 은닉 상태를 결정\n",
    "        하지만 그래디언트 손실은 계속적으로 발생\n",
    "\n",
    "    GRU\n",
    "        LSTM의 연산을 간단히 만들고 그래디언트 손실을 해결하기 위해 개발"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
