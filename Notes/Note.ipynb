{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95aff241-a87a-49f6-b086-306f91bd5ce6",
   "metadata": {},
   "source": [
    "<pre>\n",
    "데이터의 특성을 분석 - AI\n",
    "데이터의 특성을 추출(전문가 - 사전처리)하고 모델에 학습 - Machine Learning\n",
    "데이터(Raw Data)를 넣으면 특성을 추출 - Deep Learning\n",
    "\n",
    "basic - 입력 데이터를 가지고 데이터의 특성을 분석한 후에 결과 도출 (by Programmer)\n",
    "Input -> BlackBox(Programmer) -> Output\n",
    "\n",
    "ai - 입력 데이터와  결과를 보고 데이터의 특성을 도출 (by AI)\n",
    "Input & Output -> BlackBox(AI)(학습을 통해서)\n",
    "학습된 후 - new Input -> BlackBox(AI) -> Predicted Output\n",
    "\n",
    "입력 데이터 종류\n",
    "File\n",
    "Library Included DataSet\n",
    "URL\n",
    "\n",
    "태스트용(test)과 학습용(train)으로 분리(보통 3:7)\n",
    "\n",
    "                  Fit      Predict   Accuracy(test의 결과와 predict의 결과를 비교)\n",
    "모델 구축 -> 학습 -> 예측 -> 결과(평가)\n",
    "\n",
    "Predict -> 학습을 통해서 특성을 도출하고 테스트 데이터에 대한 예측한 결과를 도출\n",
    "\n",
    "지니 계수\t- 불순도를 나타내는 수치\n",
    "불순도\t- 분류한 데이터에서 다른 종류의 데이터가 섞여있는 수치\n",
    "\n",
    "DT(Decision Tree)\n",
    "\t- 의사결정트리\n",
    "\t- 조건에 따른 결과 유추\n",
    "\t- 지니 계수를 낮추는 작업 => 분류\n",
    "\n",
    "\n",
    "앙상블 \t- 여러 개의 모델을 사용하여 제일 좋은 성능을 내는 모델을 선택\n",
    "BootStrapping \t- 복원 추출\n",
    "\t\t\t- 동일한 데이터셋에서 여러 개의 샘플을 만듦\n",
    "\t\t\t- 중복 허용\n",
    "\n",
    "RF(Random Forest)  \n",
    "\t- 여러 개의 의사결정트리를 앙상블\n",
    "\t- \n",
    "\n",
    "LR(Logistic Regression) \n",
    "\n",
    "SVM(Support Vector Machine)\n",
    "\t- 기준선에서 가장 가까운 두 데이터를 서포트 벡터(Support Vectors)라고 부름\n",
    "\t- 두 데이터의 가장 가까운 거리를 마진(margin)이라 부름\n",
    "\t- 거리를 구한 뒤 역으로 선을 그으면 경계가 생김\n",
    "\n",
    "\n",
    "\n",
    "기울기(weight - w)와 절편(bias - b)\n",
    "wx + b = y\n",
    "기울기와 절편으로 데이터의 특성을 추론 가능\n",
    "\n",
    "KNN - K-Nearest Neighbor - 지도 학습 - 입력 데이터의 결과를 예측하는 것이 목적 - k = 비교하려는 인접한 데이터의 개수 = n_neighbor\n",
    "인접한 데이터를 근거로 결과를 도출 \n",
    "k는 모델의 성능이 더 이상 줄어들지 않을 때의 값이 최적\n",
    "\n",
    "머신러닝에서 결과(Label)은 숫자가 아니여도 상관없음\n",
    "딥러닝에서는 결과(Label)은 숫자여야함\n",
    "\n",
    "머신러닝을 예외로한 모든 문자를 숫자로 변환 => Encoding => LabelEncoder\n",
    "\n",
    "데이터 EDA\n",
    "1. 결과의 갯수 확인 ->value_counts()\n",
    "2. 결측치 확인 후 제거 == 학습에 영향 없는 column 삭제 or 평균으로 사용  ->isnull().sum()\n",
    "3. 특성명 확인 ->columns\n",
    "\n",
    "머신러닝은 pandas와 numpy가 상관이 없음\n",
    "딥러닝은 numpy로 변환을 해야함\n",
    "\n",
    "pandas.dataframe = column 명과 값이 있는 것\n",
    "column을 마음대로 조작 가능\n",
    "\n",
    "numpy = 배열이기에 마음대로 조작은 힘들지만 연산은 빠름\n",
    "\n",
    "\n",
    "\n",
    "샘플링 편향\n",
    "\n",
    "\n",
    "\n",
    "학습\n",
    "\t- 데이터를 바탕으로 규칙(분포 || 특성)을 습듭\n",
    "\n",
    "\t\tUnderFitting \t|\tOverFitting(과적합)\n",
    "\n",
    "의미\t\t학습 부족\t\t|\t학습 과도\n",
    "\n",
    "좋지 않음\t데이터의 특성\t|\t데이터의 노이즈\n",
    "\t\t이해 부족\t\t|\t까지도 해석\n",
    "\n",
    "이유\t\t학습 데이터 부족\t|\t데이터의 노이즈까지 학습\n",
    "\t\t일반화 능력 부족\t|\t복잡한 모델 사용\n",
    "\t\t단순 모델 사용\t|\t\n",
    "\n",
    "해결방법\t데이터 추가\t\t|\t비교적 단순한 모델 사용\n",
    "\t\t비교적 복잡한\t|\t데이터를 단순하게 만듦\n",
    "\t\t모델로 교체\t\t|\n",
    "\n",
    "\n",
    "데이터 특성이 비슷할 때 => 결과 또한 비슷\n",
    "데이터 특성이 서로 다를 때 => 결과에 차이가 큼\n",
    "\n",
    "교차 검증\n",
    "\t- 데이터를 약간의 차이를 두어서 학습시킨 후에 평균\n",
    "\t- 학습 데이터와 테스트 데이터의 공정성 부여\n",
    "\t- 데이터의 특성이 다르기 때문에\n",
    "\t- k Fold -> k 개의 데이터셋을 분류\n",
    "\n",
    "\t- Training _ Test Cross\n",
    "\t- Training Data -> 학습 데이터\n",
    "\t- Test Data -> 테스트 데이터\n",
    "\n",
    "\t- Training _ Validtaion Cross\n",
    "\t- Validation Data -> 학습 데이터를 검증하기 위한 데이터\n",
    "\n",
    "그리드 서치\n",
    "\t- 범위를 설정해주면 범위 내에서 모든 값으로 학습\n",
    "\t-> 하이퍼파라미터 튜닝\n",
    "\n",
    "하이퍼파라미터 튜닝\n",
    "\t- 모델의 성능을 최적으로 하기 위해서 모델의 중요 파라미터의 값을 최적으로 맞추는 작업\n",
    "\n",
    "회귀\n",
    "\t- 숫자로된 데이터를 예측하는 알고리즘\n",
    "\t- X와 Y의 상관관계를 구하는 알고리즘\n",
    "\n",
    "\t- 상관계수\n",
    "\t\t- X와 Y가 얼마나 관계를 가지고 있는지\n",
    "\t\t- R^2을 사용\n",
    "\t\t-> 음수의 값을 없애기 위해\n",
    "\t\t- 예측한 값과 실제 값과 맞으면 0에 가까워 짐\n",
    "146.p\n",
    "Y = coef_ * X + intercept_\n",
    "\n",
    ".coef_\t\t=> 기울기\n",
    ".intercept_\t=> 절편\n",
    "\n",
    "특성 엔지니어링\n",
    "\t- 기존의 특성에서 새로운 특성을 만들거나 변환하는 작업\n",
    "\t- 새로운 특성을 만들었을 경우 특성 간의 상관관계가 적은 것이 좋음\n",
    "\n",
    "163.p\n",
    "규제\n",
    "\t- 과적합 방지\n",
    "\t- 불필요한 가중치를 줄이거나 모델의 복잡도를 줄이는 기법\n",
    "\t\tNorm 1(L1)\t\t| \tNorm 2(L2)\n",
    "\n",
    "\t\t불필요한 특성을\t|\t불필요한 특성의\n",
    "\t\t0으로 변환\t\t|\t값을 0에 가깝게 낮춤\n",
    "\n",
    "\t\tLasso\t\t\t|\tRidge\n",
    "\t\n",
    "\n",
    "EarlyStopping\n",
    "\t- 학습 상태가 최상일 때 학습을 조기 종료\n",
    "\n",
    "딥러닝\n",
    "\t- 레이블의 연관성을 끊는다. -> 원-핫 인코딩\n",
    "\t- 데이터를 숫자로 변환 => Numpy로 변환\n",
    "\n",
    "input_shape=(입력 특성의 개수, )\n",
    "분류 개수, activation='Last-Layer activation'\n",
    "compiile(, 'Loss_Function', )</pre>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
