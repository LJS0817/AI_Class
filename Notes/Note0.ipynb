{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a52bad21-3bd3-44a8-8e54-3e11a1295ccd",
   "metadata": {},
   "source": [
    "    dense layer는 여러 입력을 하나로 모아 하나의 출력\n",
    "    \t이미지 데이터에서는 데이터의 연산이 어려움\n",
    "    \tN개의 입력을 하나로 추출\n",
    "    \n",
    "    CNN 데이터의 수가 많아지지만 작은 그룹으로 묶어서 여러 개의 출력\n",
    "    \tN개의 입력을 필터(작은 그룹) 단위로 추출\n",
    "    \t필터를 여러 개 사용하여 다양한 특징 추출\n",
    "    \n",
    "    convolution 연산(합성곱)\n",
    "    기존 데이터 * 필터  == >  두 함수를 곱하여 새로운 특징을 만들기 위해서 사용\n",
    "    \n",
    "    필터 값은 학습하면서 결정\n",
    "    풀링 데이터의 크기를 줄이는 작업(정보 축약)\n",
    "    \t최댓값, 평균값, 최솟값 ...\n",
    "    \t데이터 값이 일부 이동하더라도 처리 가능\n",
    "    \n",
    "    스트라이드 \n",
    "        필터를 옮기는 거리\n",
    "    패딩 \n",
    "        필터 내의 빈 값 처리 방법\n",
    "    \tValid  -  데이터 내에서만\n",
    "    \tSame   -  벗어날 수 있으며 벗어난 데이터는 임의의 데이터로 채울 수 있음\n",
    "    \n",
    "    2차원 데이터이기에 dense 평탄화(1차원 형태로  flatten layer ->출력)\n",
    "\n",
    "    데이터 부족\n",
    "        레이블이 없는 데이터가 부족\n",
    "        => 한정된 데이터에서 여러 가지로 변형하여 새로운 데이터를 만들어 냄\n",
    "        => 데이터 증대 \n",
    "        => 데이터의 다양성이 없어짐\n",
    "        \n",
    "    사전 학습 ( Pretrained Network )\n",
    "        이미 구축되어 있는 모델을 사용하여 새로이 레이어를 추가 후 학습 시킴\n",
    "        이미 구축되어 있는 레이어들은 훈련시키지 않음\n",
    "            => 검증되어 있는 모델을 활용 가능\n",
    "            => 학습 시간 단축 가능\n",
    "\n",
    "    미세 조정 ( Fine-Tuning )\n",
    "        전체 모델을 훈련하여 설정되어 있는 값들을 조정\n",
    "        이미 최적화되어 있기에 조정이 조금 이루어짐\n",
    "\n",
    "    MLP\n",
    "        Dense net 전체 특징에 대해서 계산, 특징 간의 관계가 훼손됨\n",
    "        CNN 일부 특징에 대해서 계산\n",
    "\n",
    "        Pre-Trained Model\n",
    "            이미 훈련된/디자인된 모델을 그대로 사용\n",
    "            네트워크 앞 부분은 일반적인 특징을 추출하지만 뒤로 갈수록 구체적으로 변하기 때문에 뒷 부분만 바꿔주면 모델을 재사용할 수 있음\n",
    "\n",
    "        Fine Tuning ( 미세조정 )\n",
    "            이미 훈련된 모델은 정답에 근사한 값을 가지고 있기 때문에 뒤에 넣은 모델에 맞게 다시 전체를 학습하여도 앞 부분은 값을 조정하는 범위가 작음\n",
    "\n",
    "        Data Argumentation\n",
    "            데이터가 적기 때문에 데이터를 늘리는 기술\n",
    "            데이터가 부족 -> 과소적합 발생\n",
    "            데이터가 많아질 수 있지만 다양성이 여전히 부족할 수 있음\n",
    "\n",
    "            SMOTE\n",
    "                주변 위치에 근사한 위치에 새로운 데이터 생성하여 데이터의 양을 늘림\n",
    "                Under-Sampling\n",
    "                    소수의 데이터 양에 맞추어서 랜덤으로 비교적 많은 데이터를 뽑아 줄이는 방법\n",
    "                Over-Sampling\n",
    "                    소수의 데이터 양을 늘리는 방법\n",
    "\n",
    "    RNN ( 순환신경망 )\n",
    "        시계열 데이터\n",
    "            과거 사건과 현재 사건이 연관되어 있음\n",
    "\n",
    "        CNN은 현재 입력에 대해서만 결과를 도출하만\n",
    "        RNN은 현재 입력만 처리하는 것이 아닌 현재 입력과 과거의 은닉 상태에 대해서 처리\n",
    "        \n",
    "        Ht = fW(Ht-1, xt)\n",
    "        Ht = 은닉 생태 = tanh(WxxT + WhHt-1)\n",
    "        xt = 입력\n",
    "        출력 = f(W*Ht)\n",
    "        fW = 가중치 W\n",
    "        \n",
    "        순환 데이터\n",
    "            Sliding Window\n",
    "                순환 신경망을 학습시키려면 데이터를 일정한 길이( Window Size )로 잘라서 여러 개의 훈련 샘플을 만들어야 함\n",
    "                \n",
    "        일대일\n",
    "            단일 입력 단일 출력\n",
    "        일대다\n",
    "            단일 입력 다중 출력\n",
    "        다대일\n",
    "            다중 입력 단일 출력\n",
    "        다대다\n",
    "            다중 입력 다중 출력\n",
    "\n",
    "        BPTT ( Backpropagation Through Time ) ( 시간에 따른 역전파 )\n",
    "            레이어가 많아짐으로 인해서 그레디언트 폭발, 손실 발생\n",
    "\n",
    "            그래디언트 클리핑\n",
    "                그래디언트 폭발이 발생하면 일정 수준 이하로 변경\n",
    "\n",
    "    LSTM ( Long Short Term Memory )\n",
    "        RNN의 그래디언트 손실 발생 문제를 해결하기 위해 개발\n",
    "        셀 = 장기 기억에 저장\n",
    "        업데이트 = 셀 정보를 선택적으로 업데이트\n",
    "        게이트 = 셀에 정보를 저장할 것인지 판단\n",
    "            삭제 게이트 = 관련 없는 셀 정보를 삭제\n",
    "            저장 ( 입력 ) 게이트 = 셀에 어떠한 정보를 저장할 것인지 ( 입력과 은닉 상태에 대해서 시그모이드 ( 0 ~ 1 ) )\n",
    "            출력 게이트 = 다름 은닉 상태를 결정\n",
    "        하지만 그래디언트 손실은 계속적으로 발생\n",
    "\n",
    "    GRU\n",
    "        LSTM의 연산을 간단히 만들고 그래디언트 손실을 해결하기 위해 개발"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
